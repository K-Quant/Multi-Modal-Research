# AAAI 
## 2023
1. MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25100)
> * Multi-modal medical data 
3. Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25113)
> *  Video-text retrieval task
> *  A joint cross-modal encoder with the triplet input of [vision, tag, text] and perform two additional supervised tasks, Video Text Matching (VTM) and Masked Language Modeling (MLM).
4. Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer.
5. PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25177)
6. Multi-Modality Deep Network for Extreme Learned Image Compression.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25184)
> * Text-Image 
> * Adopt the image-text attention module and image-request complement module to better fuse image and text features
7. Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25219)
8. M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities. 
9. Efficient End-to-End Video Question Answering with Pyramidal Multimodal Transformer. 
10. Just Noticeable Visual Redundancy Forecasting: A Deep Multimodal-Driven Approach.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25399)
> * Homologous multimodal information: saliency, depth, and segmentation.  
11. Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25445)
> *  keyword-based diverse image retrieval
12. TOT：Topology-Aware Optimal Transport for Multimodal Hate Detection.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25614)
13. Causal Conditional Hidden Markov Model for Multimodal Traffic Prediction.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25619)
> * Multi-modal traffic flow
14. Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25643)
> * Multi-modal medical data 
15. Sparse Maximum Margin Learning from Multimodal Human Behavioral Patterns.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25676)
16. MNER-QG: An End-to-End MRC Framework for Multimodal Named Entity Recognition with Query Grounding.[Link](https://ojs.aaai.org/index.php/AAAI/article/view/25971)
> * Text-Image
17. Mutual-Enhanced Incongruity Learning Network for Multi-Modal Sarcasm Detection.
18. Accommodating Audio Modality in CLIP for Multimodal Processing. [Link](https://ojs.aaai.org/index.php/AAAI/article/view/26153)
> * Vision-Language-Audio multimodal
## 2022

# Workshops
Proceedings of the Workshop on Multi-Modal Fake News and Hate-Speech Detection (DE-FACTIFY 2022) co-located with the Thirty-Sixth AAAI Conference on Artificial Intelligence ( AAAI 2022), Virtual Event, Vancouver, Canada, February 27, 2022. CEUR Workshop Proceedings 3199, CEUR-WS.org 2022

# ICML
## 2023


1. Provable Dynamic Fusion for Low-Quality Multimodal Data.[Link](https://arxiv.org/pdf/2306.02050.pdf)
> * Introducing dynamic fusion mechanism to multimodal information fusion 
2. Calibrating Multimodal Learning.[Link](https://openreview.net/pdf?id=4PgzyLz6hi)
> * A novel regularization technique to calibrate the predictive confidence of previous methods.
3. π-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation.[Link](https://proceedings.mlr.press/v202/wu23t/wu23t.pdf)
4. Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling.[Link](https://proceedings.mlr.press/v202/zhang23v/zhang23v.pdf)
>* Medical Prediction
5. MEWL: Few-shot multimodal word learning with referential uncertainty.[Link](https://arxiv.org/pdf/2306.00503.pdf)
>* This paper introduces the MachinE Word Learning (MEWL) benchmark to assess how machines learn word meaning in grounded visual scenes.

# NeurIPS
## 2023
Injecting Multimodal Information into Rigid Protein Docking via Bi-level Optimization[[link](https://openreview.net/pdf?id=ZuaVKlWdD2)]

[DATASET]M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models[[link](https://openreview.net/pdf?id=hJPATsBb3l)]

Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception[[link](https://openreview.net/pdf?id=uTlKUAm68H)]

Mass-Producing Failures of Multimodal Systems with Language Models[[link](https://openreview.net/pdf?id=T6iiOqsGOh)]

VLATTACK: Multimodal Adversarial Attacks on Vision-Language Tasks via Pre-trained Models[[link](https://openreview.net/pdf?id=qBAED3u1XZ)]

RH-BrainFS: Regional Heterogeneous Multimodal Brain Networks Fusion Strategy[[link](https://openreview.net/pdf?id=s97ezbqoDZ)]

Integration-free Training for Spatio-temporal Multimodal Covariate Deep Kernel Point Processes[[link](https://openreview.net/pdf?id=Yvpenkym8A)]

Module-wise Adaptive Distillation for Multimodality Foundation Models[[link](https://openreview.net/pdf?id=JhQP33aMx2)]

Guide Your Agent with Adaptive Multimodal Rewards[[link](https://openreview.net/pdf?id=G8nal7MpIQ)]

DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models[[link](https://openreview.net/pdf?id=ktYjrgOENR)]

A Theory of Multimodal Learning[[link](https://openreview.net/pdf?id=7xlrdSOm3g)]

Multimodal Deep Learning Model Unveils Behavioral Dynamics of V1 Activity in Freely Moving Mice[[link](https://openreview.net/pdf?id=qv5UZJTNda)]

Foundation Model is Efficient Multimodal Multitask Model Selector[[link](https://openreview.net/pdf?id=2ep5PXEZiw)]

Into the LAION’s Den: Investigating Hate in Multimodal Datasets[[link](https://openreview.net/pdf?id=6URyQ9QhYv)]

MuSe-GNN: Learning Unified Gene Representation From Multimodal Biological Graph Data[[link](https://openreview.net/pdf?id=4UCktT9XZx)]

ASIF: Coupled Data Turns Unimodal Models to Multimodal without Training[[link](https://openreview.net/pdf?id=XjOj3ZmWEl)]

[DATASET]Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A Comprehensive Benchmark for Evaluating Foundation Models in Emergency Medicine[[link](https://openreview.net/pdf?id=aKnWIrDPiR)]

SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs[[link](https://openreview.net/pdf?id=CXPUg86A1D)]

[DATASET]Intelligent Knee Sleeves: A Real-time Multimodal Dataset for 3D Lower Body Motion Estimation Using Smart Textile[[link](https://openreview.net/pdf?id=T3FKjN4p8d)]

[DATASET]DATACOMP: In search of the next generation of multimodal datasets[[link](https://openreview.net/pdf?id=dVaWCDMBof)]

[DATASET]Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with Text[[link](https://openreview.net/pdf?id=tOd8rSjcWz)]

Generating Images with Multimodal Language Models[[link](https://openreview.net/pdf?id=Uczck6TlSZ)]

Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework[[link](https://openreview.net/pdf?id=J1gBijopla)]

[DATASET]YouTubePD: A Multimodal Benchmark for Parkinson’s Disease Analysis[[link](https://openreview.net/pdf?id=AIeeXKsspI)]

[DATASET]Improving multimodal datasets with image captioning[[link](https://openreview.net/pdf?id=VIRKdeFJIg)]

MultiModN—Multimodal, Multi-Task, Interpretable Modular Networks[[link](https://openreview.net/pdf?id=iB3Ew6z4WL)]

[DATASET]Perception Test: A Diagnostic Benchmark for Multimodal Video Models[[link](https://openreview.net/forum?id=HYEGXFnPoq)]

[SPOTLIGHT]4M: Massively Multimodal Masked Modeling[[link](https://openreview.net/pdf?id=TegmlsD8oQ)]

[DATASET]HOH: Markerless Multimodal Human-Object-Human Handover Dataset with Large Object Count[[link](https://openreview.net/pdf?id=7bghy0Gq75)]

Beyond Unimodal: Generalising Neural Processes for Multimodal Uncertainty Estimation[[link](https://openreview.net/pdf?id=xq1QvViDdW)]

[DATASET]Learning to Taste : A Multimodal Wine Dataset[[link](https://openreview.net/pdf?id=VeJgZYhT7H)]

Incomplete Multimodality-Diffused Emotion Recognition[[link](https://openreview.net/pdf?id=BuGFwUS9B3)]

RegBN: Batch Normalization of Multimodal Data with Regularization[[link](https://openreview.net/pdf?id=nUbdkXqC8R)]

[DATASET]ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab[[link](https://openreview.net/pdf?id=846X3N11bf)]

[DATASET]INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis and Prognosis[[link](https://openreview.net/pdf?id=3sRR2u72oQ)]

Parameter-efficient Tuning of Large-scale Multimodal Foundation Model[[link](https://openreview.net/pdf?id=pT8DIhsJCw)]

[TIME SERIES]FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space[[link](https://openreview.net/pdf?id=l4CZCKXoSn)]

Achieving Cross Modal Generalization with Multimodal Unified Representation[[link](https://openreview.net/forum?id=t7ZowrDWVw)]

[DATASET]StressID: a Multimodal Dataset for Stress Identification[[link](https://openreview.net/pdf?id=qWsQi9DGJb)]

Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting[[link](https://openreview.net/pdf?id=ixVAXsdtJO)]

[DATASET]AircraftVerse: A Large-Scale Multimodal Dataset of Aerial Vehicle Designs[[link](https://openreview.net/pdf?id=MfhJWSp3Ea)]

Implicit Differentiable Outlier Detection Enables Robust Deep Multimodal Analysis[[link](https://openreview.net/pdf?id=jooPcatnVF)]

Training Transitive and Commutative Multimodal Transformers with LoReTTa[[link](https://openreview.net/pdf?id=nArzDm353Y)]

Brain encoding models based on multimodal transformers can transfer across language and vision[[link](https://openreview.net/pdf?id=UPefaFqjNQ)]

## 2022
Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing[[link](https://proceedings.neurips.cc/paper_files/paper/2022/file/e095c0a3717629aa5497601985bfcf0e-Paper-Conference.pdf)]

Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning[[link](https://proceedings.neurips.cc/paper_files/paper/2022/file/702f4db7543a7432431df588d57bc7c9-Paper-Conference.pdf)]

M4I: Multi-modal Models Membership Inference[[link](https://proceedings.neurips.cc/paper_files/paper/2022/file/0c79d6ed1788653643a1ac67b6ea32a7-Paper-Conference.pdf)]

OTKGE: Multi-modal Knowledge Graph Embeddings via Optimal Transport[[link](https://proceedings.neurips.cc/paper_files/paper/2022/file/ffdb280e7c7b4c4af30e04daf5a84b98-Paper-Conference.pdf)]

Deep Multi-Modal Structural Equations For Causal Effect Estimation With Unstructured Proxies[[link](Deep Multi-Modal Structural Equations For Causal Effect Estimation With Unstructured Proxies)]


